# Robot_Localization Project
### By Kenta Terasaki and Mihir Vemuri

## Particle Filter Description

In the context of our robot localization, we have developed a comprehensive architecture for implementing a particle filter. This particle filter aims to solve the problem of localizing a robot within a given map by leveraging information from both lidar and odometry readings. The primary objective is to provide a reliable pose estimation that can subsequently be utilized in various applications, such as path planning algorithms or similar processes. While our current implementation is still a work in progress and not performing as expected, all the individual components of the particle filter have been meticulously put in place. The next steps involve rigorous testing to pinpoint the areas where the algorithm is exhibiting incorrect behavior and to refine its performance.

## Vizualization of Motion Propogation
Every particle must adjust its position and orientation according to the robot's movement, which is denoted by a modification in the transformation from the base_link to the odom frame. The changes in the robot's odometry, specifically in terms of position and orientation, serve as the basis for updating the location and orientation of each particle. This update occurs within an imaginary base_link frame, with each particle at the center of its respective frame, as depicted in the illustration below.
![Screenshot from 2023-10-16 22-11-19](https://github.com/MihirV17/robot_localization/assets/123433158/41c862f6-74bb-468e-86b8-19f2c3605e8c)

The image presented illustrates the probability distribution of the particles. It focuses on how these particles are distributed in various directions, and this distribution pattern changes in response to the updated movements of the robot. In essence, it visually represents how the uncertainty or probability associated with each particle's position and orientation evolves as the robot moves and provides new information. The directions and orientations of the particles shift and adapt in accordance with the robot's latest movements, reflecting the dynamic nature of the localization or tracking process.

![image](https://github.com/MihirV17/robot_localization/assets/123433158/8f058b29-32b7-4366-82a8-e64cf30b4aaf)


## Code Planning
In our particle filter implementation, we've adopted a structured approach centered around the primary node pf.py. This central node is responsible for managing key components of the system, including a Map of the MAC, robot movement, and LIDAR data on the map. These components collectively enable the particle filter to perform its localization task effectively.

In our model, the Map of the Mac is responsible for representing and maintaining the map of the environment. It serves as a reference for the robot to understand its surroundings and make informed decisions. Robot movement encompasses the tracking of the robot's movement using odometry readings. It helps predict the potential positions of the robot based on its past actions and movements. The Lidar data on the map deals with integrating lidar sensor data, which is crucial for estimating the robot's position and orientation within the map. The ParticleFilter node efficiently manages the subscription and publication to various ROS (Robot Operating System) topics, facilitating the exchange of information between different components. It also handles the distribution of particles, maintaining a list of "ParticleDistribution" objects, which collectively represent potential robot poses. This architectural design allows for a streamlined and modular approach to particle filtering, enhancing the maintainability and expandability of the system while ensuring that the particle filter can accurately estimate the robot's position within the given environment.

![image](https://github.com/MihirV17/robot_localization/assets/123433158/9720f5a2-0bbe-40bb-8ec1-2fbfae77d412)
##### Figure 1: Overall Code Planning Approach

## Code Implementation
### initialize_particle_cloud
![image](https://github.com/MihirV17/robot_localization/assets/123433158/39a3a4c1-7cde-4b14-be7b-697364f1eba3)
##### Figure 2: particle_cloud Flow Diagram 
The provided code defines a method, `initialize_particle_cloud`, within a class, aimed at initializing a particle cloud for a robotic system. A particle cloud is a collection of particles utilized for tasks such as probabilistic localization and mapping in robotics. This method takes two parameters: `self`, a reference to the class instance, and `timestamp`. Additionally, there is an optional parameter, `xy_theta`, which signifies the mean position and orientation of the particle cloud. When `xy_theta` is not provided, the method defaults to using the robot's odometry for initialization. The core purpose of this method is to create and set up particles for the particle cloud, often involving steps like normalizing particle weights and updating the robot's pose. The particles are initialized in a circular shape with random scattering, introducing randomness through scaling factors for position and orientation. A loop iterates a specified number of times, creating particles with random positions and orientations derived from the mean values and scaling factors. These particles are then added to the particle cloud, stored in a list.

### update_particles_with_laser
![image](https://github.com/MihirV17/robot_localization/assets/123433158/328edf99-338c-4193-bd3c-74ba84610974)
##### Figure 3: laser_update flow diagram
The update_particles_with_laser function is designed to adjust the weights of particles in response to laser scan data within a robotic system. Laser scan data consists of distance readings (r) to obstacles and the corresponding angles (theta) relative to the robot's frame. The method iterates through each particle within the particle cloud and computes their updated weight based on the incoming laser data. It starts by initializing a base weight of 0.01 for each particle. For each distance reading, it checks its validity, ensuring that it's a positive, non-infinite value. It then calculates the position of the obstacle in the world frame based on the distance, angle, and the particle's current position and orientation. Next, it determines the closest obstacle distance at that position using an occupancy field. If this distance is not NaN and falls below a predefined threshold (0.2), the weight of the particle is increased by 1.0. This weight adjustment reflects a better match with the observed obstacles, indicating the particle's improved alignment with the laser scan data. Ultimately, the updated weight is assigned to the particle's w attribute, serving the purpose of enhancing particle localization based on laser data, a crucial aspect in robotic navigation and mapping tasks. The specifics of the occupancy_field and the underlying occupancy grid are not detailed in this code snippet but are essential in determining particle weights based on proximity to obstacles.

### update_particles_with_odom
![image](https://github.com/MihirV17/robot_localization/assets/123433158/8bcf53f7-ec10-42e8-bae6-711591d8cf40)
##### Figure 4: odom_update flow diagram
The code presents a method named update_particles_with_odom designed for updating all particles based on newly obtained odometry information in a robotic system. The purpose of this method is to compute the change in position and orientation (delta) between the odometry when the particles were last updated and the current odometry. This change is expressed as a tuple (x, y, theta). The method begins by converting the current odometry pose (odom_pose) into a tuple representing the pose in terms of x, y, and theta using the convert_pose_to_xy_and_theta function from a transform_helper. If there's previously stored odometry information (current_odom_xy_theta), the code calculates the change in orientation (delta_theta) between the old and new odometry poses. Next, it constructs transformation matrices (m_old and m_new) to represent the transformation from the robot's frame at the old and new odometry poses, respectively. It then computes the transformation matrix m_delta that characterizes the change in pose between the old and new odometry. The code then iterates through each particle in the particle cloud. For each particle, it applies the computed transformation matrix m_delta to update the particle's position and orientation in the world frame. This is done by converting the particle's pose into a transformation matrix, multiplying it with m_delta, and extracting the updated x, y, and theta values from the resulting matrix. Finally, the code updates the current_odom_xy_theta with the newly computed odometry information. This method is vital for keeping the particle cloud synchronized with the robot's pose changes due to odometry updates, which is crucial for accurate localization and mapping in robotic applications.

### resample_particles
![image](https://github.com/MihirV17/robot_localization/assets/123433158/194e49d6-1959-4b4d-bbb3-1501a50fb271)
##### Figure 5: resample_particles flow diagram
The code defines a method called resample_particles within a robotic system. This method is responsible for resampling particles according to their respective weights, where each particle's weight defines the probability of its selection in the resampling process, a crucial step in particle filter-based algorithms. Before the resampling, there is an initial call to normalize_particles to ensure that the weight distribution among particles is properly normalized. The core of the resampling process is as follows: first, a list named weightlist is created to store the weights of all particles in the particle cloud. Then, the method utilizes a helper function named draw_random_sample from an external helper_functions.py module to perform the resampling. This function selects particles randomly, giving higher chances to those with greater weights. After the resampling step, there is an additional step of introducing Gaussian noise to the resampled particles. The position (x and y) of each particle is perturbed by random values drawn from a Gaussian distribution with a mean (loc) of the original position and a standard deviation (scale) of 0.05. The orientation (theta) of each particle is similarly perturbed using a Gaussian distribution with a mean of the original orientation and a standard deviation of 0.1. Finally, the weights of all resampled particles are set to be uniform (1.0 divided by the total number of particles). The code concludes by updating the particle cloud with the resampled and perturbed particles. This resampling step is essential in particle filter-based localization and mapping algorithms, as it helps maintain a diverse set of particles that represent the robot's possible poses in the presence of uncertainty and sensor noise.

### update_robot_pose
![image](https://github.com/MihirV17/robot_localization/assets/123433158/a0a509ab-ea5b-4257-94cb-4e07e516dfe3)
##### Figure 6: robot_pose_update flow diagram
The code defines a method called update_robot_pose that is responsible for updating the estimated pose of the robot based on the updated particle cloud. This is a crucial step in robot localization and mapping. The method first ensures that the particle weights are normalized by invoking the normalize_particles method. Then, it proceeds to update the robot's pose. The code offers two logical methods for updating the robot's pose: either computing the mean pose of the particles or determining the most likely pose, which corresponds to the mode of the distribution. In this implementation, the code chooses the latter approach by finding the particle with the highest weight in the particle cloud. It initializes a best particle with a weight of 0.0 and iterates through all particles in the particle cloud. If a particle has a weight greater than the current best weight, it updates the best particle. After identifying the particle with the highest weight, the code sets the robot's pose to match that particle's pose using the as_pose method. If the robot has odometry data, the code also fixes the transformation between the map and odometry frames based on this updated robot pose. In case odometry data is not available, a warning message is logged. Overall, this code efficiently updates the robot's pose based on the particle cloud, with the flexibility to choose between mean and mode-based estimates.

## Strength and Pitfall

### Matrix Multiplication for updating particles with odom (Strength)

Our code utilizes matrix multiplication as an efficient method to update the robot's odometry. This approach is well-founded for several reasons. It leverages homogeneous transformation matrices, specifically "m_old" and "m_new," to encode not only translation but also rotation and potential scaling factors. By using matrix multiplication, the code can efficiently apply these transformations to a cloud of particles that represent potential positions and orientations of the robot. This batch processing of particles is computationally efficient and benefits from optimizations provided by libraries like NumPy. Moreover, the code correctly calculates the inverse of the "m_old" matrix, ensuring that particles can be accurately transferred from the previous odometry frame to the new one. Additionally, it appropriately handles changes in orientation for each particle. In summary, the decision to use matrix multiplication in this code is well-justified, offering an efficient and mathematically robust approach to update odometry for a particle cloud as the robot moves.

### Overwriting code for efficiency (Pitfall)

Our original implementation of the code did not work and was essentially not utilized because it it spawned the particles on the map in a very particular way that did not work when trying to update our particles with odom. This code was inefficient and had to be overwritten to make our code actually work It caused issues in terms of figuring out different problems, and made us stuck on some concepts for longer than we needed to be. 

## Potential Alterations

A more advisable strategy for the project might have been to initiate with the implementation of basic filtering operations on just one or two particles, ensuring a complete understanding of the entire algorithm's workflow, and subsequently crafting a more sophisticated architecture capable of scaling up to handle multiple particles. The primary challenge we faced with our initial approach stemmed from having a comprehensive architectural plan in place, but lacking a clear understanding of how all the individual components would interact or what fundamental problems might emerge when we progressed to the full-scale implementation. Expanding on this, the idea is to start with a Minimum Viable Product (MVP) or a simplified version of the project. By initially working on a smaller scale, we could focus on specific components, ensuring they function correctly before integrating them into a more extensive and intricate architecture. This iterative approach minimizes the risk of overlooking critical issues that might arise when dealing with a larger, interconnected system, ultimately leading to a more robust and well-informed final implementation.
